{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df21babf-5c06-4694-b8d0-d6cbb93d9f5a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "sess = sagemaker.Session()\n",
    "# sagemaker session bucket -> used for uploading data, models and logs\n",
    "# sagemaker will automatically create this bucket if it not exists\n",
    "sagemaker_session_bucket=None\n",
    "if sagemaker_session_bucket is None and sess is not None:\n",
    "    # set to default bucket if a bucket name is not given\n",
    "    sagemaker_session_bucket = sess.default_bucket()\n",
    "\n",
    "sess = sagemaker.Session(default_bucket=sagemaker_session_bucket)\n",
    "\n",
    "print(f\"sagemaker bucket: {sess.default_bucket()}\")\n",
    "print(f\"sagemaker session region: {sess.boto_region_name}\")\n",
    "\n",
    "iam = boto3.client('iam')\n",
    "role = iam.get_role(RoleName='<SAGEMAKER_ROLE>')['Role']['Arn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e07f5f2-369a-40ee-a7ca-8b275ebf032f",
   "metadata": {},
   "outputs": [],
   "source": [
    "repository = \"sentence-transformers/msmarco-distilbert-base-tas-b\"\n",
    "model_id=repository.split(\"/\")[-1]\n",
    "s3_location=f\"s3://{sess.default_bucket()}/custom_inference/{model_id}/model.tar.gz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0430ab2c-7817-4032-8382-2795be2264b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://huggingface.co/$repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c5de8e-276f-4f63-a514-80307016fb5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp -r code/ $model_id/code/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0035bbf-1184-4a57-9a3e-dfdbb30cc3bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd $model_id\n",
    "!tar zcvf model.tar.gz *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2490800e-650e-4f36-9d7c-11ae7534a425",
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 cp model.tar.gz $s3_location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02401a3b-93f4-47c5-bdbc-43e193fb7b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.huggingface.model import HuggingFaceModel\n",
    "from sagemaker.serverless import ServerlessInferenceConfig\n",
    "\n",
    "# create Hugging Face Model Class\n",
    "huggingface_model = HuggingFaceModel(\n",
    "   model_data=s3_location,       # path to your model and script\n",
    "   role=role,                    # iam role with permissions to create an Endpoint\n",
    "   transformers_version=\"4.26.0\",  # transformers version used\n",
    "   pytorch_version=\"1.13.1\",        # pytorch version used\n",
    "   py_version='py39',            # python version used\n",
    ")\n",
    "\n",
    "serverless_config = ServerlessInferenceConfig(\n",
    "    memory_size_in_mb=2048, max_concurrency=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc2130e-5559-4285-93b0-79ea090fa041",
   "metadata": {},
   "outputs": [],
   "source": [
    "# deploy the endpoint endpoint\n",
    "predictor = huggingface_model.deploy(\n",
    "    endpoint_name=\"msmarco-distilbert-base-tas-b\",\n",
    "    serverless_inference_config=serverless_config,\n",
    ")\n",
    "\n",
    "# initial_instance_count=1,\n",
    "# instance_type=\"ml.m5.xlarge\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856c5270-32a4-4b64-9341-9b33090355ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete endpoint config if needed - cannot do this on SageMaker GUI\n",
    "sess.delete_endpoint_config(\"msmarco-distilbert-base-tas-b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3027c6f6-cd2c-4465-ad21-f9cb4347a374",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test `inference.py`\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "#CLS Pooling - Take output from first token\n",
    "def cls_pooling(model_output):\n",
    "    return model_output.last_hidden_state[:, 0]\n",
    "\n",
    "def model_fn(model_dir):\n",
    "    # Load model from HuggingFace Hub\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_dir)\n",
    "    model = AutoModel.from_pretrained(model_dir)\n",
    "    model.eval()  # only inference\n",
    "\n",
    "    return model.to(device), tokenizer\n",
    "\n",
    "def predict_fn(data, model_and_tokenizer):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        data (dict): dict of request JSON with sentence in \"inputs\"\n",
    "        NOTE we predict embeddings only for the first sentence\n",
    "    \"\"\"\n",
    "\n",
    "    model, tokenizer = model_and_tokenizer\n",
    "    \n",
    "    # Tokenize sentences\n",
    "    sentence = data.pop(\"inputs\", data)[0]\n",
    "    encoded_input = tokenizer(sentence, padding=True,\n",
    "                              truncation=True, return_tensors='pt').to(device)\n",
    "\n",
    "    # Compute token embeddings\n",
    "    with torch.no_grad():\n",
    "        model_output = model(**encoded_input, return_dict=True)\n",
    "\n",
    "    # Perform pooling\n",
    "    embedding = cls_pooling(model_output)\n",
    "\n",
    "    return {\"embedding\": embedding[0].cpu().tolist()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b712ea34-4681-4b02-a676-5467f80b0a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, tokenizer = model_fn(repository)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137ce9e3-0874-45cd-9f15-f220df520217",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\"inputs\": [\"hello\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9879c7ad-5431-48b8-8d93-8fdc3c08af46",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb = predict_fn(data, (model, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ac8906-d3d8-42ea-a931-c512a76e79cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c304ff8c-8ab8-4ef1-ba46-dec8f0271790",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:foodvisor] *",
   "language": "python",
   "name": "conda-env-foodvisor-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
